{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating n-grams from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Users MUST shutdown kernels!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('popular', halt_on_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk as nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = '/project/msca/kadochnikov/data/books/book_11-0.txt'\n",
    "book_short = '/project/msca/kadochnikov/data/books/3boat10_short.txt'\n",
    "book_out = '/project/msca/kadochnikov/books/book_11-0_out.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the ten most common words in book - what is this book about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1686),\n",
       " ('and', 869),\n",
       " ('to', 799),\n",
       " ('a', 672),\n",
       " ('of', 606),\n",
       " ('I', 543),\n",
       " ('it', 540),\n",
       " ('she', 509),\n",
       " ('said', 456),\n",
       " ('in', 414)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "words = re.findall(r'\\w+', open(book).read())\n",
    "Counter(words).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1818),\n",
       " ('and', 940),\n",
       " ('to', 809),\n",
       " ('a', 690),\n",
       " ('of', 631),\n",
       " ('it', 610),\n",
       " ('she', 553),\n",
       " ('i', 543),\n",
       " ('you', 481),\n",
       " ('said', 462)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercasing the words\n",
    "import re\n",
    "from collections import Counter\n",
    "words = re.findall(r'\\w+', open(book).read().lower())\n",
    "Counter(words).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept of n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('quick', 'brown', 'fox', 'jumps', 'over')\n",
      "('brown', 'fox', 'jumps', 'over', 'the')\n",
      "('fox', 'jumps', 'over', 'the', 'lazy')\n",
      "('jumps', 'over', 'the', 'lazy', 'dog')\n"
     ]
    }
   ],
   "source": [
    "sentence = 'quick brown fox jumps over the lazy dog'\n",
    "n = 5\n",
    "kgrams = nltk.ngrams(sentence.split(), n)\n",
    "for grams in kgrams:\n",
    "    print (grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 3722 samples and 38329 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 2565),\n",
       " ('’', 1769),\n",
       " ('the', 1681),\n",
       " ('‘', 1116),\n",
       " ('.', 901),\n",
       " ('and', 863),\n",
       " ('to', 794),\n",
       " ('a', 671),\n",
       " ('of', 603),\n",
       " ('I', 543)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying NLTK\n",
    "f = open(book)\n",
    "raw = f.read()\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(raw)\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>2565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>’</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‘</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>to</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>of</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word  Frequency\n",
       "0    ,       2565\n",
       "1    ’       1769\n",
       "2  the       1681\n",
       "3    ‘       1116\n",
       "4    .        901\n",
       "5  and        863\n",
       "6   to        794\n",
       "7    a        671\n",
       "8   of        603\n",
       "9    I        543"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_df = pd.DataFrame(fdist.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "fdist_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring bi-grams and tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(book)\n",
    "raw = f.read()\n",
    "\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "#Create your bigrams or trigrams\n",
    "bgs = nltk.bigrams(tokens)\n",
    "tgs = nltk.trigrams(tokens)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "fdist_2 = nltk.FreqDist(bgs)\n",
    "fdist_3 = nltk.FreqDist(tgs)\n",
    "\n",
    "fdist_2_df = pd.DataFrame(fdist_2.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_3_df = pd.DataFrame(fdist_3.most_common(),\n",
    "                    columns=['Word', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17292, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(,, and)</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(., ‘)</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(,, ’)</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(’, said)</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(!, ’)</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(’, ‘)</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(’, t)</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(said, the)</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(’, s)</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(,, ‘)</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Frequency\n",
       "0     (,, and)        456\n",
       "1       (., ‘)        427\n",
       "2       (,, ’)        397\n",
       "3    (’, said)        329\n",
       "4       (!, ’)        282\n",
       "5       (’, ‘)        241\n",
       "6       (’, t)        216\n",
       "7  (said, the)        206\n",
       "8       (’, s)        204\n",
       "9       (,, ‘)        199"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fdist_2_df.shape)\n",
    "\n",
    "fdist_2_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28479, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(,, ’, said)</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(’, said, the)</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(’, said, Alice)</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(., ‘, I)</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(!, ’, said)</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(,, ’, the)</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(I, ’, m)</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(*, *, *)</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(don, ’, t)</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Alice, ., ‘)</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Frequency\n",
       "0      (,, ’, said)        215\n",
       "1    (’, said, the)        203\n",
       "2  (’, said, Alice)        115\n",
       "3         (., ‘, I)         69\n",
       "4      (!, ’, said)         65\n",
       "5       (,, ’, the)         59\n",
       "6         (I, ’, m)         57\n",
       "7         (*, *, *)         54\n",
       "8       (don, ’, t)         51\n",
       "9     (Alice, ., ‘)         50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fdist_3_df.shape)\n",
    "\n",
    "fdist_3_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creting custom n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(*, *, *, *, *)</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(the, Project, Gutenberg, Literary, Archive)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Project, Gutenberg, Literary, Archive, Founda...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(to, the, Project, Gutenberg, Literary)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(in, a, tone, of, great)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Will, you,, won’t, you,, will)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(you,, won’t, you,, will, you,)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(won’t, you,, will, you,, won’t)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(you,, will, you,, won’t, you,)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(the, terms, of, this, agreement)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Word  Frequency\n",
       "0                                    (*, *, *, *, *)         48\n",
       "1       (the, Project, Gutenberg, Literary, Archive)         11\n",
       "2  (Project, Gutenberg, Literary, Archive, Founda...          9\n",
       "3            (to, the, Project, Gutenberg, Literary)          6\n",
       "4                           (in, a, tone, of, great)          4\n",
       "5                    (Will, you,, won’t, you,, will)          4\n",
       "6                    (you,, won’t, you,, will, you,)          4\n",
       "7                   (won’t, you,, will, you,, won’t)          4\n",
       "8                    (you,, will, you,, won’t, you,)          4\n",
       "9                  (the, terms, of, this, agreement)          4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this way we are not limited to bigrams and trigrams only.\n",
    "n = 5\n",
    "ngrams = nltk.ngrams(raw.split(), n)\n",
    "\n",
    "\n",
    "fdist_n = nltk.FreqDist(ngrams)\n",
    "\n",
    "fdist_n_df = pd.DataFrame(fdist_n.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_n_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(*, *, *, *, *, *, *, *, *, *)</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(join, the, dance?, Will, you,, won’t, you,, w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(the, dance?, Will, you,, won’t, you,, will, y...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(This, eBook, is, for, the, use, of, anyone, a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(eBook, is, for, the, use, of, anyone, anywher...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(is, for, the, use, of, anyone, anywhere, at, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(for, the, use, of, anyone, anywhere, at, no, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(the, use, of, anyone, anywhere, at, no, cost,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(use, of, anyone, anywhere, at, no, cost, and,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(of, anyone, anywhere, at, no, cost, and, with...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Word  Frequency\n",
       "0                     (*, *, *, *, *, *, *, *, *, *)         33\n",
       "1  (join, the, dance?, Will, you,, won’t, you,, w...          3\n",
       "2  (the, dance?, Will, you,, won’t, you,, will, y...          3\n",
       "3  (This, eBook, is, for, the, use, of, anyone, a...          2\n",
       "4  (eBook, is, for, the, use, of, anyone, anywher...          2\n",
       "5  (is, for, the, use, of, anyone, anywhere, at, ...          2\n",
       "6  (for, the, use, of, anyone, anywhere, at, no, ...          2\n",
       "7  (the, use, of, anyone, anywhere, at, no, cost,...          2\n",
       "8  (use, of, anyone, anywhere, at, no, cost, and,...          2\n",
       "9  (of, anyone, anywhere, at, no, cost, and, with...          2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this way we are not limited to bigrams and trigrams only.\n",
    "n = 10\n",
    "ngrams = nltk.ngrams(raw.split(), n)\n",
    "\n",
    "\n",
    "fdist_n = nltk.FreqDist(ngrams)\n",
    "\n",
    "fdist_n_df = pd.DataFrame(fdist_n.most_common(),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "fdist_n_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/project/msca/kadochnikov/books/book_11-0_out.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-566804219afa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Create your n-grams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/project/msca/kadochnikov/books/book_11-0_out.txt'"
     ]
    }
   ],
   "source": [
    "f2 = open(book_out, \"w\")\n",
    "\n",
    "\n",
    "#Create your n-grams\n",
    "n = 6\n",
    "sixgrams = nltk.ngrams(raw.split(), n)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "fdist = nltk.FreqDist(sixgrams)\n",
    "for k,v in fdist.items():\n",
    "    #print k,v\n",
    "    f2.write(str(k)+\"\\t\"+str(v)+\"\\n\")\n",
    "    \n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l /home/kadochnikov/data/books/book_11-0_out*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## While we can also apply dictionary-based clean-up algorithms, they are not going to work on Big Data applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "\n",
    "#default_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "f = open(book)\n",
    "raw = f.read()\n",
    "\n",
    "words = nltk.tokenize.word_tokenize(raw)\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove single-character tokens (mostly punctuation)\n",
    "words = [word for word in words if len(word) > 1]\n",
    "\n",
    "# Remove numbers\n",
    "#words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "# Remove punctuation\n",
    "words = [word for word in words if word.isalpha()]\n",
    "\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "words = [word.lower() for word in words]\n",
    "\n",
    "# Remove stopwords\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
